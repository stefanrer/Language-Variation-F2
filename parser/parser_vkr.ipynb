{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:49.802453Z",
     "start_time": "2024-06-12T18:43:49.800362Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "# !python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:49.829271Z",
     "start_time": "2024-06-12T18:43:49.812877Z"
    }
   },
   "id": "4f26d2fa38ee805f",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Token: # trees parse\n",
    "    def __init__(self, token_text: str = \"\", token_type: str = \"\", token_lemma: str = \"\", token_form_id: int = 0, token_lemma_id: int = 0, token_homonymous: bool = False, token_properties: dict = {}):\n",
    "        self.token_text = token_text\n",
    "        self.token_type = token_type\n",
    "        self.token_lemma = token_lemma\n",
    "        self.token_form_id = token_form_id\n",
    "        self.token_lemma_id = token_lemma_id\n",
    "        self.token_homonymous = token_homonymous\n",
    "        self.token_properties = token_properties\n",
    "        self.hide_zero_prop()\n",
    "\n",
    "    def hide_zero_prop(self):\n",
    "        new_properties = {}\n",
    "        for token_property in self.token_properties:\n",
    "            if \"0-\" not in self.token_properties[token_property]:\n",
    "                new_properties[token_property] = self.token_properties[token_property]\n",
    "        self.token_properties = new_properties\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"token_text: {self.token_text}, token_lemma: {self.token_lemma}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.token_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:49.836487Z",
     "start_time": "2024-06-12T18:43:49.830266Z"
    }
   },
   "id": "6ef76dcb5600e1d2",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = KeyedVectors.load_word2vec_format('../W2V_Model/model.bin', binary=True)  # ruwikiruscorpora_upos_cbow_300_10_2021\n",
    "nlp = spacy.load('ru_core_news_lg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.640566Z",
     "start_time": "2024-06-12T18:43:49.847010Z"
    }
   },
   "id": "a5c36b367fceb41c",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"correct_trees.pickle\", \"rb\") as p_file:\n",
    " correct_trees = pickle.load(p_file)\n",
    "with open(\"bad_trees.pickle\", \"rb\") as p_file:\n",
    " bad_trees = pickle.load(p_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.645825Z",
     "start_time": "2024-06-12T18:43:52.642101Z"
    }
   },
   "id": "2811a33c4aecb3b9",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"scenarios.json\", \"r\", encoding=\"utf8\") as in_file:\n",
    "    scenarios = json.load(in_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.662320Z",
     "start_time": "2024-06-12T18:43:52.646908Z"
    }
   },
   "id": "3aafe4d4b86d4215",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'@поклониться_15804_999': {'CENTRAL': {'scenarios': {'гость поклонился королю': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.20885194001495166,\n             'tree_proximity': 0.20885194001495166,\n             'scenario': '@поклониться_15804_999'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'поклониться',\n            'wordform': 'поклонился'},\n           {'valency_alias': 'ag', 'lemma': 'гость', 'wordform': 'гость'},\n           {'valency_alias': 'ben',\n            'lemma': 'король',\n            'wordform': 'королю'}]}]}]}}}},\n  'BEFORE': {'scenarios': {'гость пришёл к королю': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.2761527398489404,\n             'tree_proximity': 0.2761527398489404,\n             'scenario': '@прийти_4121_VERB_13'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'прийти',\n            'wordform': 'пришел'},\n           {'valency_alias': 'ag', 'lemma': 'гость', 'wordform': 'гость'},\n           {'valency_alias': 'targ',\n            'lemma': 'король',\n            'wordform': 'королю'}]}]}]}}}},\n  'INTERP': {'scenarios': {'гость приветствовал короля': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.1855530066445392,\n             'tree_proximity': 0.1855530066445392,\n             'scenario': '@поблагодарить_15315_1421'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'приветствовать',\n            'wordform': 'приветствовал'},\n           {'valency_alias': 'ag', 'lemma': 'гость', 'wordform': 'гость'},\n           {'valency_alias': 'pat',\n            'lemma': 'король',\n            'wordform': 'короля'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.1855530066445392,\n             'tree_proximity': 0.1855530066445392,\n             'scenario': '@поблагодарить_15315_1421'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'приветствовать',\n            'wordform': 'приветствовал'},\n           {'valency_alias': 'ag', 'lemma': 'гость', 'wordform': 'гость'},\n           {'valency_alias': 'pat',\n            'lemma': 'король',\n            'wordform': 'короля'}]}]}]}},\n    'гость поблагодарил короля': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.1951452777257324,\n             'tree_proximity': 0.1951452777257324,\n             'scenario': '@поблагодарить_15315_1421'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'поблагодарить',\n            'wordform': 'поблагодарил'},\n           {'valency_alias': 'ag', 'lemma': 'гость', 'wordform': 'гость'},\n           {'valency_alias': 'pat',\n            'lemma': 'король',\n            'wordform': 'короля'}]}]}]}}}}},\n '@искать_1845_VERB_2': {'CENTRAL': {'scenarios': {'полиция искала преступника': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.34891784890912775,\n             'tree_proximity': 0.34891784890912775,\n             'scenario': '@искать_1845_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'искать',\n            'wordform': 'искала'},\n           {'valency_alias': 'ag', 'lemma': 'полиция', 'wordform': 'полиция'},\n           {'valency_alias': 'pat',\n            'lemma': 'преступник',\n            'wordform': 'преступника'}]}]}]}}}},\n  'BEFORE': {'scenarios': {'преступник совершил преступление': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.33454724996490487,\n             'tree_proximity': 0.33454724996490487,\n             'scenario': '@совершить_19153_VERB_3'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'совершить',\n            'wordform': 'совершил'},\n           {'valency_alias': 'ag',\n            'lemma': 'преступник',\n            'wordform': 'преступник'},\n           {'valency_alias': 'pat',\n            'lemma': 'преступление',\n            'wordform': 'преступление'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.27233955114057873,\n             'tree_proximity': 0.27233955114057873,\n             'scenario': '@совершить_19153_VERB_4'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'совершить',\n            'wordform': 'совершил'},\n           {'valency_alias': 'ag',\n            'lemma': 'преступник',\n            'wordform': 'преступник'},\n           {'valency_alias': 'voc',\n            'lemma': 'преступление',\n            'wordform': 'преступление'}]}]}]}}}},\n  'AFTER': {'scenarios': {'полиция нашла преступника': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.25645109931872584,\n             'tree_proximity': 0.25645109931872584,\n             'scenario': '@найти_2729_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'найти',\n            'wordform': 'нашла'},\n           {'valency_alias': 'ag', 'lemma': 'полиция', 'wordform': 'полиция'},\n           {'valency_alias': 'cont',\n            'lemma': 'преступник',\n            'wordform': 'преступника'}]}]}]}},\n    'полиция не нашла преступника': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.2585437829487418,\n             'tree_proximity': 0.2585437829487418,\n             'scenario': '@искать_1845_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'найти',\n            'wordform': 'нашла'},\n           {'valency_alias': 'ag', 'lemma': 'полиция', 'wordform': 'полиция'},\n           {'valency_alias': 'pat',\n            'lemma': 'преступник',\n            'wordform': 'преступника'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.25645109931872584,\n             'tree_proximity': 0.25645109931872584,\n             'scenario': '@найти_2729_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'найти',\n            'wordform': 'нашла'},\n           {'valency_alias': 'ag', 'lemma': 'полиция', 'wordform': 'полиция'},\n           {'valency_alias': 'cont',\n            'lemma': 'преступник',\n            'wordform': 'преступника'}]}]}]}}}},\n  'INTERP': {'scenarios': {'преступник скрывался от полиции': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.2894784155236909,\n             'tree_proximity': 0.2894784155236909,\n             'scenario': '@исчезать_1873_VERB_3'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'скрываться',\n            'wordform': 'скрывался'},\n           {'valency_alias': 'ag',\n            'lemma': 'преступник',\n            'wordform': 'преступник'},\n           {'valency_alias': 'ca',\n            'lemma': 'полиция',\n            'wordform': 'полиции'}]}]}]}}}}},\n '@встретиться_707_VERB_1': {'CENTRAL': {'scenarios': {'женщина встретилась глазами с матерью': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.35821698241706557,\n             'tree_proximity': 0.35821698241706557,\n             'scenario': '@встретиться_707_VERB_1'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'встретиться',\n            'wordform': 'встретилась'},\n           {'valency_alias': 'ag', 'lemma': 'женщина', 'wordform': 'женщина'},\n           {'valency_alias': 'instr', 'lemma': 'глаз', 'wordform': 'глазами'},\n           {'valency_alias': 'ca',\n            'lemma': 'матерь',\n            'wordform': 'матерью'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.35635521171132856,\n             'tree_proximity': 0.35635521171132856,\n             'scenario': '@встретиться_707_VERB_1'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'встретиться',\n            'wordform': 'встретилась'},\n           {'valency_alias': 'ag', 'lemma': 'женщина', 'wordform': 'женщина'},\n           {'valency_alias': 'instr', 'lemma': 'глаз', 'wordform': 'глазами'},\n           {'valency_alias': 'ca', 'lemma': 'мать', 'wordform': 'матерью'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.319566266389601,\n             'tree_proximity': 0.18003831989373528,\n             'scenario': '@встретиться_707_VERB_1'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'встретиться',\n            'wordform': 'встретилась'},\n           {'valency_alias': 'ag', 'lemma': 'женщина', 'wordform': 'женщина'},\n           {'valency_alias': 'instr',\n            'lemma': 'глаз',\n            'wordform': 'глазами'}]},\n         {'meta': {'metadata': {'semantics_proximity': {'proximity': 0.04051037339786954,\n             'tree_proximity': 0.18003831989373528,\n             'scenario': '@человек_SA_1'}}},\n          'valencies': [{'valency_alias': 'sa',\n            'lemma': 'мать',\n            'wordform': 'матерью'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.319566266389601,\n             'tree_proximity': 0.18003831989373528,\n             'scenario': '@встретиться_707_VERB_1'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'встретиться',\n            'wordform': 'встретилась'},\n           {'valency_alias': 'ag', 'lemma': 'женщина', 'wordform': 'женщина'},\n           {'valency_alias': 'instr',\n            'lemma': 'глаз',\n            'wordform': 'глазами'}]},\n         {'meta': {'metadata': {'semantics_proximity': {'proximity': 0.04051037339786954,\n             'tree_proximity': 0.18003831989373528,\n             'scenario': '@человек_SA_1'}}},\n          'valencies': [{'valency_alias': 'sa',\n            'lemma': 'матерь',\n            'wordform': 'матерью'}]}]}]}}}},\n  'INTERP': {'scenarios': {'женщина смотрела на мать': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.2751983427699913,\n             'tree_proximity': 0.2751983427699913,\n             'scenario': '@смотреть_4923_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'смотреть',\n            'wordform': 'смотрела'},\n           {'valency_alias': 'ag', 'lemma': 'женщина', 'wordform': 'женщина'},\n           {'valency_alias': 'targ',\n            'lemma': 'мать',\n            'wordform': 'мать'}]}]}]}},\n    'мать смотрела на женщину': {'semantics': {'semantics': [{'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.2489622171509019,\n             'tree_proximity': 0.2489622171509019,\n             'scenario': '@смотреть_4923_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'смотреть',\n            'wordform': 'смотрела'},\n           {'valency_alias': 'ag', 'lemma': 'мать', 'wordform': 'мать'},\n           {'valency_alias': 'targ',\n            'lemma': 'женщина',\n            'wordform': 'женщину'}]}]},\n       {'facts': [{'meta': {'metadata': {'semantics_proximity': {'proximity': 0.22548477219827273,\n             'tree_proximity': 0.22548477219827273,\n             'scenario': '@смотреть_4923_VERB_2'}}},\n          'valencies': [{'valency_alias': 'p',\n            'lemma': 'смотреть',\n            'wordform': 'смотрела'},\n           {'valency_alias': 'cont', 'lemma': 'мать', 'wordform': 'мать'},\n           {'valency_alias': 'targ',\n            'lemma': 'женщина',\n            'wordform': 'женщину'}]}]}]}}}}}}"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.677320Z",
     "start_time": "2024-06-12T18:43:52.663817Z"
    }
   },
   "id": "3da8269b1b1853e6",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"vals.json\", \"r\", encoding=\"UTF8\") as j_file:\n",
    "    valencies = json.load(j_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.684747Z",
     "start_time": "2024-06-12T18:43:52.678907Z"
    }
   },
   "id": "486a17845bf83092",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def branch():\n",
    "    return defaultdict(list)\n",
    "\n",
    "with open(\"incidents_dict.pkl\", \"rb\") as p_file:\n",
    "    incidents_dict = pickle.load(p_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.708555Z",
     "start_time": "2024-06-12T18:43:52.685705Z"
    }
   },
   "id": "78a80b45fd441358",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_best_semantics(semantics):\n",
    "    try:\n",
    "        return sorted(semantics, key=lambda x: (len(x['facts']), -x['facts'][0]['meta']['metadata']['semantics_proximity']['tree_proximity']) if x['facts'] else (0, 0))[0]\n",
    "    except:\n",
    "        return semantics[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.713826Z",
     "start_time": "2024-06-12T18:43:52.709801Z"
    }
   },
   "id": "8c9cc48d9c082ae1",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_incidents(lemma, relation):\n",
    "    incidents = incidents_dict[lemma][relation]\n",
    "    if incidents == {}:\n",
    "        return []\n",
    "    incidents.sort(key=lambda x: x[1], reverse=True)\n",
    "    return incidents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.722435Z",
     "start_time": "2024-06-12T18:43:52.714837Z"
    }
   },
   "id": "51a59bb7d5bf778",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_similarity_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.728748Z",
     "start_time": "2024-06-12T18:43:52.723930Z"
    }
   },
   "id": "7764c23522eb1094",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def intersect_check_for_compactness(words, compare_word, threshold = 0.15, show_plot: bool = False, debug: bool = False):\n",
    "    if debug: print(f\"in words: {len(words)}\")\n",
    "    remaining_words = []\n",
    "    max_similarity = 0\n",
    "    similarities = {}\n",
    "    if compare_word not in model:\n",
    "        print(f\"compare word not in w2v model\")\n",
    "        return remaining_words\n",
    "    \n",
    "\n",
    "    # Create a word cloud center from the vectors of words\n",
    "    words_vectors = np.array([model[word[0]] for word in words if word[0] in model])\n",
    "    word_cloud_center = np.mean(words_vectors, axis=0)\n",
    "    \n",
    "    for word in words:\n",
    "        if word[0] in model:\n",
    "            word_vector = model[word[0]]  \n",
    "        else:\n",
    "            continue\n",
    "        # Calculate cosine similarity with the word cloud center\n",
    "        similarity = cosine_similarity(word_cloud_center.reshape(1, -1), word_vector.reshape(1, -1))\n",
    "        similarities[word] = similarity[0][0]\n",
    "        if similarity[0][0] > max_similarity:\n",
    "            max_similarity = similarity[0][0]\n",
    "    max_similarity_list.append(max_similarity)\n",
    "    # Calculate the threshold as the median of the similarities but not less than a constant\n",
    "    if similarities:\n",
    "        threshold = max(np.median(list(similarities.values())), threshold)\n",
    "    # Convert the dictionary to a list of tuples\n",
    "    similarities_list = [(word, sim) for word, sim in similarities.items()]\n",
    "\n",
    "    # Sort the list by similarity and then by frequency in descending order\n",
    "    similarities_list = sorted(similarities_list, key=lambda x: (x[1], x[0][1]), reverse=True)\n",
    "\n",
    "    # Now you can iterate over the sorted list\n",
    "    for word, similarity in similarities_list:\n",
    "        # Remove words further than the threshold (precision error correction)\n",
    "        if similarity < threshold:\n",
    "            continue\n",
    "        # Add words closer to the threshold to W1, but not included in the set\n",
    "        remaining_words.append(f\"{word[0]}_sim:{'{:.3f}'.format(round(similarity, 3))}_freq:{word[1]}\")\n",
    "        \n",
    "    if debug: print(f\"similarities: {similarities}\")\n",
    "    return remaining_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.738162Z",
     "start_time": "2024-06-12T18:43:52.729739Z"
    }
   },
   "id": "8ffd3f65217c8426",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_tokens(scenario_tokens, p_list, possible_pairs, word_lemma_to_wordform, word_wordform_to_lemma, central_possible_pairs, text, central_scenario_text, central_wordform_to_lemma, scenario_type, outfile, debug: bool = False):\n",
    "        p_properties = {}\n",
    "        p_tokens = scenario_tokens['root']\n",
    "        for p_token in p_tokens:\n",
    "            if p_token.token_text in p_list:\n",
    "                p_properties.setdefault(p_token.token_text, []).extend(token_property for token_property in p_token.token_properties if token_property in valencies)\n",
    "        if debug: print(\"p_properties:\", p_properties)\n",
    "        paired_words_properties = {}\n",
    "        for p_token, words in scenario_tokens.items():\n",
    "            if p_token == 'root' or p_token not in p_list:\n",
    "                continue\n",
    "            for word in words:\n",
    "                if debug: print(\"try match:\",word, possible_pairs)\n",
    "                if word.token_text in possible_pairs:\n",
    "                    if 'SemVal' not in word.token_properties:\n",
    "                        continue\n",
    "                    sem_val = word.token_properties['SemVal']\n",
    "                    for p, properties in p_properties.items():\n",
    "                        for p_property in properties:\n",
    "                            val = p_property.split(\"-\")[-1]\n",
    "                            if sem_val == val:\n",
    "                                paired_words_properties[word_lemma_to_wordform[word.token_text]] = {word_lemma_to_wordform[p]: valencies[p_property]}\n",
    "        if debug: print(\"paired_words_properties:\", paired_words_properties)\n",
    "        #else:\n",
    "            #print(f\"paired_words_properties: {paired_words_properties}\", file=outfile)\n",
    "        found_variants = {}\n",
    "        polysemy = None\n",
    "        central_polysemy = None\n",
    "        selected_valency = None\n",
    "        central_selected_valency = None\n",
    "        for val in paired_words_properties:\n",
    "            if val not in central_possible_pairs:\n",
    "                continue\n",
    "            scenario_verb_lemma, scenario_relationship = list(paired_words_properties[val].items())[0]\n",
    "            if debug: print(f\"scenario_verb_lemma, scenario_relationship: {scenario_verb_lemma, scenario_relationship}\")\n",
    "            if type(scenario_relationship) == list:\n",
    "                if debug: print(f\"polysemy detected in {scenario_type} scenario: {scenario_relationship}\")\n",
    "                polysemy = f\"polysemy detected in {scenario_type} scenario: {scenario_relationship}\"\n",
    "                scenario_incidents_selector = []\n",
    "                for scenario_val in scenario_relationship:\n",
    "                    scenario_incidents_selector.append(get_incidents(scenario_verb_lemma, scenario_val))\n",
    "                scenario_incidents = max(scenario_incidents_selector, key=len)\n",
    "                if debug: print(f\"selected valency for scenario: {scenario_relationship[scenario_incidents_selector.index(scenario_incidents)]}, len: {len(scenario_incidents)}\")\n",
    "                selected_valency = f\"selected valency for {scenario_type} scenario: {scenario_relationship[scenario_incidents_selector.index(scenario_incidents)]}, len: {len(scenario_incidents)}\"\n",
    "            else:\n",
    "                \n",
    "                scenario_incidents = get_incidents(scenario_verb_lemma, scenario_relationship)\n",
    "                if debug: print(f\"selected valency for scenario: {scenario_relationship}, len: {len(scenario_incidents)}\")\n",
    "                selected_valency = f\"selected valency for {scenario_type} scenario: {scenario_relationship}, len: {len(scenario_incidents)}\"\n",
    "            if debug: print(f\"scenario_incidents: {scenario_incidents}\")\n",
    "            central_scenario_verb_lemma, central_scenario_relationship = list(central_possible_pairs[val].items())[0]\n",
    "            if debug: print(f\"central_scenario_verb_lemma: {central_scenario_verb_lemma}\")\n",
    "            if type(central_scenario_relationship) == list:\n",
    "                if debug: print(f\"polysemy detected in central scenario: {central_scenario_relationship}\")\n",
    "                central_polysemy = f\"polysemy detected in central scenario: {central_scenario_relationship}\"\n",
    "                central_scenario_incidents_selector = []\n",
    "                for scenario_val in central_scenario_relationship:\n",
    "                    central_scenario_incidents_selector.append(get_incidents(central_scenario_verb_lemma, scenario_val))\n",
    "                central_scenario_incidents = max(central_scenario_incidents_selector, key=len)\n",
    "                if debug: print(f\"selected valency for central scenario: {central_scenario_relationship[central_scenario_incidents_selector.index(central_scenario_incidents)]}, len: {len(central_scenario_incidents)}\")\n",
    "                central_selected_valency = f\"selected valency for central scenario: {central_scenario_relationship[central_scenario_incidents_selector.index(central_scenario_incidents)]}, len: {len(central_scenario_incidents)}\"\n",
    "            else:\n",
    "                central_scenario_incidents = get_incidents(central_scenario_verb_lemma, central_scenario_relationship)\n",
    "                if debug: print(f\"selected valency for central scenario: {central_scenario_relationship}, len: {len(central_scenario_incidents)}\")\n",
    "                central_selected_valency = f\"selected valency for central scenario: {central_scenario_relationship}, len: {len(central_scenario_incidents)}\"\n",
    "            if debug: print(f\"central_scenario_incidents: {central_scenario_incidents}\")\n",
    "            intersect_incidents = [item for item in central_scenario_incidents if item[0] in [x[0] for x in scenario_incidents]]\n",
    "            if debug: print(f\"intersect_incidents: {intersect_incidents}\")\n",
    "            # TODO: add w2v close words\n",
    "            words_nlp = [nlp(word[0])[0] for word in intersect_incidents]\n",
    "            val_nlp = nlp(val)[0]\n",
    "            val_nlp = f\"{val_nlp.text}_{val_nlp.pos_}\"\n",
    "            if debug: print(f\"val_nlp: {val_nlp}\")\n",
    "            words_incident = [word[1] for word in intersect_incidents]\n",
    "            if debug: print([word[0] for word in intersect_incidents])\n",
    "            if debug: print(words_incident)\n",
    "            words_pos = [f\"{token.text}_{token.pos_}\" for token in words_nlp]\n",
    "            intersect_incidents_checked_with_w2v = [(word, words_incident[i]) for i, word in enumerate(words_pos) if word in model.key_to_index]\n",
    "            checked_for_compactness = intersect_check_for_compactness(intersect_incidents_checked_with_w2v, val_nlp, debug=debug)\n",
    "            if debug: print(\"intersect_incidents_checked_with_w2v:\",intersect_incidents_checked_with_w2v)\n",
    "            if debug: print(\"checked_for_compactness:\", checked_for_compactness)\n",
    "            if debug: print(f\"scenario_incidents_amount: {len(scenario_incidents)}, central_scenario_incidents: {len(central_scenario_incidents)}, w2v check: {len(intersect_incidents_checked_with_w2v)}, compact_check: {len(checked_for_compactness)}\")\n",
    "            if len(checked_for_compactness) > 0:\n",
    "                found_variants[val] = []\n",
    "                for word in checked_for_compactness:\n",
    "                    replaced_scenario_text = text.lower().replace(word_wordform_to_lemma[val], f\"({word})\")\n",
    "                    replaced_central_scenario_text = central_scenario_text.lower().replace(central_wordform_to_lemma[val], f\"({word})\")\n",
    "                    found_variants[val].append(f\"{replaced_central_scenario_text} --- {replaced_scenario_text}\")    \n",
    "        return found_variants, paired_words_properties, polysemy, central_polysemy, selected_valency, central_selected_valency"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.754101Z",
     "start_time": "2024-06-12T18:43:52.739154Z"
    }
   },
   "id": "9f9f61953107f062",
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_scenario(scenario, scenario_type, central_possible_pairs, central_scenario_text, central_wordform_to_lemma, outfile, debug: bool = False, include_central_polysemy = False):\n",
    "    for text in scenario[\"scenarios\"]:\n",
    "            if debug: print(\"text:\",text)\n",
    "            if text.lower() == 'неадекв':\n",
    "                print(\"неадекв\", file=outfile)\n",
    "                print(f\"{scenario_type}: {text.lower()}\\n\", file=outfile)\n",
    "                continue\n",
    "            scenario_semantic = scenario['scenarios'][text]['semantics']['semantics']\n",
    "            scenario_best_semantic = get_best_semantics(scenario_semantic)\n",
    "            if 'facts' not in scenario_best_semantic:\n",
    "                print(\"нету фактов\", file=outfile)\n",
    "                print(f\"{scenario_type}: {text.lower()}\\n\", file=outfile)\n",
    "                continue\n",
    "            scenario_facts = scenario_best_semantic['facts']\n",
    "            if not scenario_facts:\n",
    "                print(\"нету семантики\", file=outfile)\n",
    "                print(f\"{scenario_type}: {text.lower()}\\n\", file=outfile)\n",
    "                continue\n",
    "            semantics = [(sem['lemma'] if 'lemma' in sem else '', sem['wordform'] if 'wordform' in sem else '', sem['valency_alias'] if 'valency_alias' in sem else '') for fact in scenario_facts for sem in fact['valencies']]\n",
    "            if debug: print(\"semantics:\",semantics)\n",
    "            word_lemma_to_wordform = {lemma[1]: lemma[0] for lemma in semantics}\n",
    "            word_wordform_to_lemma = {lemma[0]: lemma[1] for lemma in semantics}\n",
    "            possible_pairs = {lemma[1] for lemma in semantics if lemma[2] != 'p' and (lemma[0] in central_possible_pairs or lemma[1] in central_possible_pairs)}\n",
    "            if debug: print(f\"possible pairs: {possible_pairs}\")\n",
    "            p_list = {lemma[1] for lemma in semantics if lemma[2] == 'p'}\n",
    "            if text.lower() in correct_trees:\n",
    "                scenario_tokens = correct_trees[text.lower()]['tokens']\n",
    "                found_variants, paired_word_properties, polysemy, central_polysemy, selected_valency, central_selected_valency = parse_tokens(scenario_tokens, p_list, possible_pairs, word_lemma_to_wordform, word_wordform_to_lemma, central_possible_pairs, text, central_scenario_text, central_wordform_to_lemma, scenario_type, outfile, debug=debug)\n",
    "                if include_central_polysemy and central_polysemy is not None:\n",
    "                    if debug: \n",
    "                        print(central_polysemy)\n",
    "                        print(central_selected_valency)\n",
    "                    else:\n",
    "                        print(central_polysemy, file=outfile)\n",
    "                        print(central_selected_valency, file=outfile)\n",
    "                if debug:\n",
    "                    print(f\"scenario found in correct_trees\")\n",
    "                else:\n",
    "                    print(f\"scenario found in correct_trees\", file=outfile)\n",
    "                if len(found_variants.keys()) > 0:\n",
    "                    if debug:\n",
    "                        print(\"parsed correct tree\")\n",
    "                        print(f\"paired word properties: {paired_word_properties}\")\n",
    "                        if polysemy is not None:\n",
    "                            print(polysemy)\n",
    "                            print(selected_valency)\n",
    "                        print(f\"Creating pairs for {scenario_type}: {text.lower()}\")\n",
    "                    else:\n",
    "                        print(\"parsed correct tree\", file=outfile)\n",
    "                        print(f\"paired word properties: {paired_word_properties}\", file=outfile)\n",
    "                        if polysemy is not None:\n",
    "                            print(polysemy, file=outfile)\n",
    "                            print(selected_valency, file=outfile)\n",
    "                        print(f\"Creating pairs for {scenario_type}: {text.lower()}\", file=outfile)\n",
    "                    for found_vars in found_variants:\n",
    "                        for var in found_variants[found_vars]:\n",
    "                            if debug:\n",
    "                                print(var)\n",
    "                            else:\n",
    "                                print(var, file=outfile)\n",
    "                    if debug:\n",
    "                        print()\n",
    "                    else:\n",
    "                        print(file=outfile)\n",
    "            else:\n",
    "                counter = 0\n",
    "                parsed_trees_counter = 0\n",
    "                paired_word_properties = {}\n",
    "                while text.lower() in bad_trees and counter < len(bad_trees[text.lower()]):\n",
    "                    scenario_tokens = bad_trees[text.lower()][counter]['tokens']\n",
    "                    found_variants, paired_word_properties, polysemy, central_polysemy, selected_valency, central_selected_valency = parse_tokens(scenario_tokens, p_list, possible_pairs, word_lemma_to_wordform, word_wordform_to_lemma, central_possible_pairs, text, central_scenario_text, central_wordform_to_lemma, scenario_type, outfile, debug)\n",
    "                    counter += 1\n",
    "                    if len(found_variants.keys()) > 0:\n",
    "                        parsed_trees_counter += 1\n",
    "                        if debug:\n",
    "                            if parsed_trees_counter == 1:\n",
    "                                if include_central_polysemy and central_polysemy is not None:\n",
    "                                    print(central_polysemy)\n",
    "                                    print(central_selected_valency)\n",
    "                                print(f\"Creating pairs for {scenario_type}: {text.lower()}\")\n",
    "                                print(f\"paired word properties: {paired_word_properties}\")\n",
    "                                if polysemy is not None:\n",
    "                                    print(polysemy)\n",
    "                                    print(selected_valency)\n",
    "                            print(f\"parsed bad tree {parsed_trees_counter}\")\n",
    "                        else:\n",
    "                            if parsed_trees_counter == 1:\n",
    "                                if include_central_polysemy and central_polysemy is not None:\n",
    "                                    print(central_polysemy, file=outfile)\n",
    "                                    print(central_selected_valency, file=outfile)\n",
    "                                print(f\"Creating pairs for {scenario_type}: {text.lower()}\", file=outfile)\n",
    "                                print(f\"paired word properties: {paired_word_properties}\", file=outfile)\n",
    "                                if polysemy is not None:\n",
    "                                    print(polysemy, file=outfile)\n",
    "                                    print(selected_valency, file=outfile)\n",
    "                            print(f\"parsed bad tree {parsed_trees_counter}\", file=outfile)\n",
    "                        for found_vars in found_variants:\n",
    "                            for var in found_variants[found_vars]:\n",
    "                                if debug:\n",
    "                                    print(var)\n",
    "                                else:\n",
    "                                    print(var, file=outfile)\n",
    "                        if debug:\n",
    "                            print()\n",
    "                        else:\n",
    "                            print(file=outfile)\n",
    "                        break # comment if want all trees\n",
    "                            \n",
    "                if parsed_trees_counter == 0:\n",
    "                    if debug:\n",
    "                        print(f\"valencies not found for any tree in Sketches, trees_parsed: {counter}\")\n",
    "                        print(f\"{scenario_type}: {text.lower()}\")\n",
    "                        print()\n",
    "                    else:\n",
    "                        print(f\"valencies not found for any tree in Sketches, trees_parsed: {counter}\", file=outfile)\n",
    "                        print(f\"{scenario_type}: {text.lower()}\\n\", file=outfile)\n",
    "                        print(file=outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.772039Z",
     "start_time": "2024-06-12T18:43:52.755351Z"
    }
   },
   "id": "80d8c5463fd88242",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(full_scenario, outfile, debug: bool = False):\n",
    "    central_scenario = scenarios[full_scenario][\"CENTRAL\"][\"scenarios\"]\n",
    "    central_scenario_text = list(central_scenario.keys())[0]\n",
    "    if debug:\n",
    "        print(f\"Parsing scenario: {full_scenario} - {central_scenario_text}\\n\")\n",
    "    else:\n",
    "        print(f\"Parsing scenario: {full_scenario} - {central_scenario_text}\\n\", file=outfile)\n",
    "    central_scenario_semantic = central_scenario[central_scenario_text]['semantics']['semantics']\n",
    "    central_scenario_best_semantic = get_best_semantics(central_scenario_semantic)\n",
    "    if 'facts' not in central_scenario_best_semantic:\n",
    "        print(central_scenario_text, \"has no facts\")\n",
    "        return\n",
    "    central_scenario_best_semantic = get_best_semantics(central_scenario_semantic)['facts']\n",
    "    semantics = [(sem['lemma'] if 'lemma' in sem else '', sem['wordform'] if 'wordform' in sem else '', sem['valency_alias'] if 'valency_alias' in sem else '') for fact in central_scenario_best_semantic for sem in fact['valencies']]\n",
    "    if debug: print(\"semantics:\", semantics)\n",
    "    word_lemma_to_wordform = {lemma[1]: lemma[0] for lemma in semantics}\n",
    "    word_wordform_to_lemma = {lemma[0]: lemma[1] for lemma in semantics}\n",
    "    possible_pairs = {lemma[1] for lemma in semantics if lemma[2] != 'p'}\n",
    "    if central_scenario_text.lower() not in correct_trees:\n",
    "        if debug:\n",
    "            print(f\"{'central scenario not in correct trees'}\\n\")\n",
    "        else:\n",
    "            print(f\"{'central scenario not in correct trees'}\\n\", file=outfile)\n",
    "        return\n",
    "    central_scenario_tokens = correct_trees[central_scenario_text.lower()]['tokens'] #\n",
    "    central_p_list = {lemma[1] for lemma in semantics if lemma[2] == 'p'}\n",
    "    central_p_properties = {}\n",
    "    p_tokens = central_scenario_tokens['root']\n",
    "    for p_token in p_tokens:\n",
    "        if p_token.token_text in central_p_list:\n",
    "            central_p_properties.setdefault(p_token.token_text, []).extend(token_property for token_property in p_token.token_properties if token_property in valencies)\n",
    "    if debug: print(\"central_p_properties:\", central_p_properties)\n",
    "    central_paired_words_properties = {}\n",
    "    for p_token, words in central_scenario_tokens.items():\n",
    "        if p_token == 'root' or p_token not in central_p_list:\n",
    "            continue\n",
    "        for word in words:\n",
    "            if word.token_text in possible_pairs or word.token_lemma in possible_pairs:\n",
    "                if 'SemVal' not in word.token_properties:\n",
    "                    continue\n",
    "                sem_val = word.token_properties['SemVal']\n",
    "                for p, properties in central_p_properties.items():\n",
    "                    for p_property in properties:\n",
    "                        val = p_property.split(\"-\")[-1]\n",
    "                        if sem_val == val:\n",
    "                            central_paired_words_properties[word_lemma_to_wordform[word.token_text]] = {word_lemma_to_wordform[p]: valencies[p_property]}\n",
    "    if debug: print(f\"central_possible words with properties: {central_paired_words_properties}\")\n",
    "    scenario_types = [\"BEFORE\", \"AFTER\", \"INTERP\"]\n",
    "    possible_types_in_current = [scenario_type for scenario_type in scenario_types if scenario_type in scenarios[full_scenario]]\n",
    "    first_scenario = True\n",
    "    for scenario_type in possible_types_in_current:\n",
    "        if debug: print(\"scenario_type:\",scenario_type)\n",
    "        parse_scenario(scenarios[full_scenario][scenario_type], scenario_type, central_paired_words_properties, central_scenario_text.lower(), word_wordform_to_lemma, outfile, debug, first_scenario)\n",
    "        first_scenario = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:43:52.790555Z",
     "start_time": "2024-06-12T18:43:52.773039Z"
    }
   },
   "id": "3f1766faa65cc49c",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parsing scenarios:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45caac0f107347bcadc4f1f9b9048297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_file = open(\"test_on_scenarios.txt\", mode=\"w\", encoding=\"UTF8\")\n",
    "with tqdm(total=len(scenarios), desc=\"Parsing scenarios\") as pbar:\n",
    "    for scenario in scenarios:\n",
    "        pbar.update()\n",
    "        scenario_text = main(scenario, res_file)\n",
    "print(f\"mean sim: {statistics.mean(max_similarity_list)}\", file=res_file)\n",
    "res_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:44:06.723349Z",
     "start_time": "2024-06-12T18:43:52.792573Z"
    }
   },
   "id": "da043c7fc18fea9f",
   "execution_count": 130
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
